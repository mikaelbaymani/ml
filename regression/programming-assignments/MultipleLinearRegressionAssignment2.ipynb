{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating Multiple Regression Coefficients (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to mikael.baymani@gmail.com and will expire on May 13, 2020.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1564478530.log\n"
     ]
    }
   ],
   "source": [
    "import graphlab\n",
    "# 1. If you’re using SFrames, import graphlab and load in the house\n",
    "# data (this is the graphlab command you can also download the csv).\n",
    "# e.g. in python with SFrames:\n",
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. If you’re using python: to do the matrix operations required to\n",
    "# perform a gradient descent we will be using the popular python library\n",
    "# ‘numpy’ which is a computational library specialized for operations on\n",
    "# arrays. For students unfamiliar with numpy we have created a numpy tutorial\n",
    "# (see useful resources). It is common to import numpy under the name ‘np’ for\n",
    "# short, to do this execute:\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1\n"
     ]
    }
   ],
   "source": [
    "print graphlab.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Next write a function that takes a data set, a list of features\n",
    "# (e.g. [‘sqft_living’, ‘bedrooms’]), to be used as inputs, and a name of\n",
    "# the output (e.g. ‘price’). This function should return a features_matrix\n",
    "# (2D array) consisting of first a column of ones followed by columns containing\n",
    "# the values of the input features in the data set in the same order as the input\n",
    "# list. It should also return an output_array which is an array of the values of\n",
    "# the output in the data set (e.g. ‘price’). e.g. if you’re using SFrames and numpy\n",
    "# you can complete the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.  , 3.  , 1.  ],\n",
       "        [1.  , 3.  , 2.25],\n",
       "        [1.  , 2.  , 1.  ],\n",
       "        ...,\n",
       "        [1.  , 2.  , 0.75],\n",
       "        [1.  , 3.  , 2.5 ],\n",
       "        [1.  , 2.  , 0.75]]),\n",
       " array([221900., 538000., 180000., ..., 402101., 400000., 325000.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # add a constant column to an SFrame\n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "    # select the columns of data_SFrame given by the ‘features’ list into the SFrame ‘features_sframe’\n",
    "    features_sframe = graphlab.SFrame()\n",
    "    for feature in features:\n",
    "        features_sframe[feature] = data_sframe[feature]\n",
    "\n",
    "    # this will convert the features_sframe into a numpy matrix with GraphLab Create >= 1.7!!\n",
    "    features_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the target to the variable ‘output_sarray’\n",
    "    output_sarray = data_sframe[output]\n",
    "\n",
    "    # this will convert the SArray into a numpy array:\n",
    "    output_array = output_sarray.to_numpy() # GraphLab Create>= 1.7!!\n",
    "    return(features_matrix, output_array)\n",
    "\n",
    "get_numpy_data(sales, [\"bedrooms\", \"bathrooms\"], \"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. If the features matrix (including a column of 1s for the constant)\n",
    "# is stored as a 2D array (or matrix) and the regression weights are stored\n",
    "# as a 1D array then the predicted output is just the dot product between\n",
    "# the features matrix and the weights (with the weights on the right).\n",
    "# Write a function ‘predict_output’ which accepts a 2D array ‘feature_matrix’\n",
    "# and a 1D array ‘weights’ and returns a 1D array ‘predictions’. e.g. in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcome(feature_matrix, weights):\n",
    "    # ŷ_i = h^T (x_i) * w\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. If we have a the values of a single input feature in an array ‘feature’\n",
    "# and the prediction ‘errors’ (predictions - output) then the derivative of\n",
    "# the regression cost function with respect to the weight of ‘feature’ is just\n",
    "# twice the dot product between ‘feature’ and ‘errors’. Write a function that\n",
    "# accepts a ‘feature’ array and ‘error’ array and returns the ‘derivative’\n",
    "# (a single number). e.g. in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    ## partial[j] = -2 * sum_(i=1)^N h_j(x_i)[y_i - ŷ_i(w^(t))]\n",
    "    derivative = 2 * np.dot(feature, errors)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Now we will use our predict_output and feature_derivative to write a gradient\n",
    "# descent function. Although we can compute the derivative for all the features\n",
    "# simultaneously (the gradient) we will explicitly loop over the features individually\n",
    "# for simplicity. Write a gradient descent function that does the following:\n",
    "\n",
    "# - Accepts a numpy feature_matrix 2D array, a 1D output array, an array of initial weights,\n",
    "#   a step size and a convergence tolerance.\n",
    "# - While not converged updates each feature weight by subtracting the step size times the\n",
    "#   derivative for that feature given the current weights\n",
    "# - At each step computes the magnitude/length of the gradient (square root of the sum of\n",
    "#   squared components)\n",
    "# - When the magnitude of the gradient is smaller than the input tolerance returns the\n",
    "#   final weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False\n",
    "    weights = np.array(initial_weights)\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights:\n",
    "        predictions = predict_outcome(feature_matrix, weights)\n",
    "        # compute the errors as predictions - output:\n",
    "        errors = predictions - output\n",
    "        \n",
    "        gradient_sum_squares = 0 # initialize the gradient\n",
    "        # while not converged, update each weight individually:\n",
    "        for i in range(len(weights)):\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            partial = feature_derivative(errors, feature_matrix[:, i])\n",
    "            \n",
    "            # add the squared derivative to the gradient magnitude\n",
    "            gradient_sum_squares += partial**2\n",
    "            \n",
    "            # update the weight based on step size and derivative:\n",
    "            weights[i] = weights[i] - step_size * partial\n",
    "            \n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Now split the sales data into training and test data. Like previous notebooks\n",
    "# it’s important to use the same seed.\n",
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Now we will run the regression_gradient_descent function on some actual data.\n",
    "# In particular we will use the gradient descent to estimate the model from Week 1\n",
    "# using just an intercept and slope. Use the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output= 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_weights = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-46999.88716555,    281.91211912])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281.9\n"
     ]
    }
   ],
   "source": [
    "# 9. Quiz Question: What is the value of the weight for sqft_living -- the second\n",
    "# element of ‘simple_weights’ (rounded to 1 decimal place)?\n",
    "print \"%.1f\" % simple_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Now build a corresponding ‘test_simple_feature_matrix’ and ‘test_output’\n",
    "# using test_data. Using ‘test_simple_feature_matrix’ and ‘simple_weights’ compute\n",
    "# the predicted house prices on all the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = predict_outcome(test_simple_feature_matrix, simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Quiz Question: What is the predicted price for the 1st house in the Test data\n",
    "# set for model 1 (round to nearest dollar)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356134\n"
     ]
    }
   ],
   "source": [
    "print \"%.0f\" % test_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Now compute RSS on all test data for this model. Record the value and store it for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSS = lambda output, predictions : sum((output - predictions)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275400047593155.7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSS(test_output, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Now we will use the gradient descent to fit a model with more than\n",
    "# 1 predictor variable (and an intercept). Use the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15']\n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features,my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_weights = regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.99999688e+04,  2.45072603e+02,  6.52795277e+01])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Use the regression weights from this second model (using sqft_living and\n",
    "# sqft_living_15) and predict the outcome of all the house prices on the TEST data.\n",
    "(test_multiple_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "test_predictions_multiple_feature = predict_outcome(test_multiple_feature_matrix, multiple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366651\n"
     ]
    }
   ],
   "source": [
    "# 15. Quiz Question: What is the predicted price for the 1st house in the TEST\n",
    "# data set for model 2 (round to nearest dollar)?\n",
    "print \"%.0f\" % test_predictions_multiple_feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathrooms': 1.0,\n",
       " 'bedrooms': 3.0,\n",
       " 'condition': 4,\n",
       " 'constant': 1,\n",
       " 'date': datetime.datetime(2014, 5, 28, 0, 0, tzinfo=GMT +0.0),\n",
       " 'floors': '1.5',\n",
       " 'grade': 7,\n",
       " 'id': '0114101516',\n",
       " 'lat': 47.75584254,\n",
       " 'long': -122.22874498,\n",
       " 'price': 310000.0,\n",
       " 'sqft_above': 1430,\n",
       " 'sqft_basement': 0,\n",
       " 'sqft_living': 1430.0,\n",
       " 'sqft_living15': 1780.0,\n",
       " 'sqft_lot': 19901,\n",
       " 'sqft_lot15': 12697.0,\n",
       " 'view': 0,\n",
       " 'waterfront': 0,\n",
       " 'yr_built': 1927,\n",
       " 'yr_renovated': 0,\n",
       " 'zipcode': '98028'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16. What is the actual price for the 1st house in the Test data set?\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Quiz Question: Which estimate was closer to the true price for the\n",
    "# 1st house on the TEST data set, model 1 or model 2?\n",
    "# Answer: Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270263446465243.97"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 18. Now compute RSS on all test data for the second model.\n",
    "# Record the value and store it for later.\n",
    "RSS(test_output, test_predictions_multiple_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Quiz Question: Which model (1 or 2) has lowest RSS on all of\n",
    "# the TEST data?\n",
    "# Answer: Model 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
