{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices using k-nearest neighbors regression\n",
    "\n",
    "In this notebook, you will implement k-nearest neighbors regression. You will:\n",
    "\n",
    "* Find the k-nearest neighbors of a given query input\n",
    "* Predict the output for the query input using the k-nearest neighbors\n",
    "* Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to mikael.baymani@gmail.com and will expire on May 13, 2020.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1565775436.log\n"
     ]
    }
   ],
   "source": [
    "import graphlab\n",
    "sales = graphlab.SFrame('kc_house_data_small.gl/')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # add a constant column to an SFrame\n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "    # select the columns of data_SFrame given by the ‘features’ list into the SFrame ‘features_sframe’\n",
    "    features_sframe = graphlab.SFrame()\n",
    "    for feature in features:\n",
    "        features_sframe[feature] = data_sframe[feature]\n",
    "\n",
    "    # this will convert the features_sframe into a numpy matrix with GraphLab Create >= 1.7!!\n",
    "    features_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the target to the variable ‘output_sarray’\n",
    "    output_sarray = data_sframe[output]\n",
    "\n",
    "    # this will convert the SArray into a numpy array:\n",
    "    output_array = output_sarray.to_numpy() # GraphLab Create>= 1.7!!\n",
    "    return(features_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    X = feature_matrix / norms\n",
    "    return  (X,norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_and_validation, test) = sales.random_split(.8, seed=1)\n",
    "(train, validation) = train_and_validation.random_split(.8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "features_train, output_train = get_numpy_data(train, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In computing distances, it is crucial to normalize features. Otherwise, for example,\n",
    "# the sqft_living feature (typically on the order of thousands) would exert a much larger\n",
    "# influence on distance than the bedrooms feature (typically on the order of ones). We\n",
    "# divide each column of the training feature matrix by its 2-norm, so that the transformed\n",
    "# column has unit norm.\n",
    "\n",
    "# IMPORTANT: Make sure to store the norms of the features in the training set. The features\n",
    "# in the test and validation sets must be divided by these same norms, so that the training,\n",
    "# test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(features_train)\n",
    "features_test = features_test / norms\n",
    "features_valid = features_valid / norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a single distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start, let's just explore computing the \"distance\" between two given houses. We will\n",
    "# take our query house to be the first house of the test set and look at the distance between\n",
    "# this house and the 10th house of the training set.\n",
    "\n",
    "# To see the features associated with the query house, print the first row (index 0) of the test\n",
    "# feature matrix. You should get an 18-dimensional vector whose components are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059\n",
      "  0.          0.05102365  0.0116321   0.01564352  0.01362084  0.02481682\n",
      "  0.01350306  0.          0.01345386 -0.01346927  0.01375926  0.0016225 ]\n"
     ]
    }
   ],
   "source": [
    "print features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now print the 10th row (index 9) of the training feature matrix. Again, you get an 18-dimensional\n",
    "# vector with components between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346254  0.01195898  0.00156612]\n"
     ]
    }
   ],
   "source": [
    "print features_train[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUIZ QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the Euclidean distance between the query house and the 10th house of the training set?\n",
    "\n",
    "# Note: Do not use the np.linalg.norm function; use np.sqrt, np.sum, and the power operator (**)\n",
    "# instead. The latter approach is more easily adapted to computing multiple distances at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05972359371666126"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance(x_j, x_q) = sqrt[ (x_j[0]-x_q[0])^2 + ... +  (x_j[d]-x_q[d])^2 ]\n",
    "np.sqrt( np.sum( (features_train[9] - features_test[0])**2 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute multiple distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of course, to do nearest neighbor regression, we need to compute the distance between our\n",
    "# query house and all houses in the training set.\n",
    "\n",
    "# To visualize this nearest-neighbor search, let's first compute the distance from our query\n",
    "# house (features_test[0]) to the first 10 houses of the training set (features_train[0:10]) \n",
    "# and then search for the nearest neighbor within this small set of houses. Through restricting\n",
    "# ourselves to a small set of houses to begin with, we can visually scan the list of 10 distances\n",
    "# to verify that our code for finding the nearest neighbor is working.\n",
    "\n",
    "# Write a loop to compute the Euclidean distance from the query house to each of the first 10 houses\n",
    "# in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.060275\n",
      "1: 0.085469\n",
      "2: 0.061499\n",
      "3: 0.053403\n",
      "4: 0.058445\n",
      "5: 0.059879\n",
      "6: 0.054631\n",
      "7: 0.055431\n",
      "8: 0.052384\n",
      "9: 0.059724\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # distance(x_j, x_q) = sqrt[ (x_j[0]-x_q[0])^2 + ... +  (x_j[d]-x_q[d])^2 ]\n",
    "    print \"%d: %f\" % (i , np.sqrt( np.sum( (features_train[i] - features_test[0])**2 ) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUIZ QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among the first 10 training houses, which house is the closest to the query house?\n",
    "# Answer: No. 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is computationally inefficient to loop over computing distances to all houses in our\n",
    "# training dataset. Fortunately, many of the Numpy functions can be vectorized, applying \n",
    "# the same operation over multiple values or vectors. We now walk through this process.\n",
    "\n",
    "# Consider the following loop that computes the element-wise difference between the features\n",
    "# of the query house (features_test[0]) and the first 3 training houses (features_train[0:3]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -3.87821276e-03 -1.20498190e-02 -1.05552733e-02\n",
      "  2.08673616e-04 -8.52950206e-03  0.00000000e+00 -5.10236549e-02\n",
      "  0.00000000e+00 -3.47633726e-03 -5.50336860e-03 -2.48168183e-02\n",
      " -1.63756198e-04  0.00000000e+00 -1.70072004e-05  1.30577772e-05\n",
      " -5.14364795e-03  6.69281453e-04]\n",
      "[ 0.00000000e+00 -3.87821276e-03 -4.51868214e-03 -2.26610387e-03\n",
      "  7.19763456e-04  0.00000000e+00  0.00000000e+00 -5.10236549e-02\n",
      "  0.00000000e+00 -3.47633726e-03  1.30705004e-03 -1.45830788e-02\n",
      " -1.91048898e-04  6.65082271e-02  4.23240653e-05  6.22415897e-06\n",
      " -2.89330197e-03  1.47606982e-03]\n",
      "[ 0.00000000e+00 -7.75642553e-03 -1.20498190e-02 -1.30002801e-02\n",
      "  1.60518166e-03 -8.52950206e-03  0.00000000e+00 -5.10236549e-02\n",
      "  0.00000000e+00 -5.21450589e-03 -8.32384500e-03 -2.48168183e-02\n",
      " -3.13866046e-04  0.00000000e+00  4.71047219e-05  1.56530415e-05\n",
      "  3.72914476e-03  1.64764925e-03]\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(3):\n",
    "    print features_train[i]-features_test[0]\n",
    "    # should print 3 vectors of length 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The subtraction operator (-) in Numpy is vectorized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00 -3.87821276e-03 -1.20498190e-02 -1.05552733e-02\n",
      "   2.08673616e-04 -8.52950206e-03  0.00000000e+00 -5.10236549e-02\n",
      "   0.00000000e+00 -3.47633726e-03 -5.50336860e-03 -2.48168183e-02\n",
      "  -1.63756198e-04  0.00000000e+00 -1.70072004e-05  1.30577772e-05\n",
      "  -5.14364795e-03  6.69281453e-04]\n",
      " [ 0.00000000e+00 -3.87821276e-03 -4.51868214e-03 -2.26610387e-03\n",
      "   7.19763456e-04  0.00000000e+00  0.00000000e+00 -5.10236549e-02\n",
      "   0.00000000e+00 -3.47633726e-03  1.30705004e-03 -1.45830788e-02\n",
      "  -1.91048898e-04  6.65082271e-02  4.23240653e-05  6.22415897e-06\n",
      "  -2.89330197e-03  1.47606982e-03]\n",
      " [ 0.00000000e+00 -7.75642553e-03 -1.20498190e-02 -1.30002801e-02\n",
      "   1.60518166e-03 -8.52950206e-03  0.00000000e+00 -5.10236549e-02\n",
      "   0.00000000e+00 -5.21450589e-03 -8.32384500e-03 -2.48168183e-02\n",
      "  -3.13866046e-04  0.00000000e+00  4.71047219e-05  1.56530415e-05\n",
      "   3.72914476e-03  1.64764925e-03]]\n"
     ]
    }
   ],
   "source": [
    "print features_train[0:3] - features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Note that the output of this vectorized operation is identical to that of the\n",
    "# loop above, which can be verified below:\n",
    "# verify that vectorization works\n",
    "results = features_train[0:3] - features_test[0]\n",
    "print results[0] - (features_train[0]-features_test[0])\n",
    "# should print all 0's if results[0] == (features_train[0]-features_test[0])\n",
    "print results[1] - (features_train[1]-features_test[0])\n",
    "# should print all 0's if results[1] == (features_train[1]-features_test[0])\n",
    "print results[2] - (features_train[2]-features_test[0])\n",
    "# should print all 0's if results[2] == (features_train[2]-features_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform 1-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the element-wise differences, it is not too hard to compute the Euclidean\n",
    "# distances between our query house and all of the training houses. First, write a single-line\n",
    "# expression to define a variable diff such that diff[i] gives the element-wise difference\n",
    "# between the features of the query house and the i-th training house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = features_train - features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the code above, run the following cell, which should output a value -0.0934339605842:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0934339605841801\n"
     ]
    }
   ],
   "source": [
    "print diff[-1].sum() # sum of the feature differences between the query and last training house\n",
    "# should print -0.0934339605842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step in computing the Euclidean distances is to take these feature-by-feature differences\n",
    "# in diff, square each, and take the sum over feature indices. That is, compute the sum of square\n",
    "# feature differences for each training house (row in diff).\n",
    "\n",
    "# By default, np.sum sums up everything in the matrix and returns a single number. To instead sum\n",
    "# only over a row or column, we need to specifiy the axis parameter described in the np.sum\n",
    "# documentation. In particular, axis=1 computes the sum across each row.\n",
    "\n",
    "# Below, we compute this sum of square feature differences for all training houses and verify that\n",
    "# the output for the 16th house in the training set is equivalent to having examined only the 16th\n",
    "# row of diff and computing the sum of squares on that row alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003307059028786791\n",
      "0.0033070590287867904\n"
     ]
    }
   ],
   "source": [
    "print np.sum(diff**2, axis=1)[15]\n",
    "print np.sum(diff[15]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this result in mind, write a single-line expression to compute the\n",
    "# Euclidean distances between the query house and all houses in the training set.\n",
    "# Assign the result to a variable distances.\n",
    "\n",
    "# Hint: Do not forget to take the square root of the sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.sqrt(np.sum(diff**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the code above, run the following cell, which should output a value 0.0237082324496:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023708232449603735\n"
     ]
    }
   ],
   "source": [
    "print distances[100] # Euclidean distance between the query house and the 101th training house\n",
    "# should print 0.0237082324496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you are ready to write a function that computes the distances from a query house\n",
    "# to all training houses. The function should take two parameters: (i) the matrix of\n",
    "# training features and (ii) the single feature vector associated with the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_neighbors(dataset, query):\n",
    "    diff = dataset - query\n",
    "    return np.sqrt(np.sum(diff**2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUIZ QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the query house to be third house of the test set (features_test[2]). What is\n",
    "# the index of the house in the training set that is closest to this query house?\n",
    "# What is the predicted value of the query house based on 1-nearest neighbor regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382\n",
      "249000\n"
     ]
    }
   ],
   "source": [
    "best_index = None\n",
    "best_distance = None\n",
    "distances = distance_to_neighbors(features_train, features_test[2])\n",
    "for i in xrange( len(distances) ):\n",
    "    distance = distances[i]\n",
    "    if best_distance is None or distance < best_distance:\n",
    "        best_distance = distance\n",
    "        best_index = i\n",
    "print best_index\n",
    "print output_train[best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For k-nearest neighbors, we need to find a set of k houses in the training set closest\n",
    "# to a given query house. We then make predictions based on these k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class PriorityQueue(object):\n",
    "    def __init__(self, key):\n",
    "        self._key = key\n",
    "        self._heap = []\n",
    "    def push(self, item):\n",
    "        heapq.heappush(self._heap, (self._key(item), item))\n",
    "    def top(self):\n",
    "        return heapq.heappop(self._heap)[1]\n",
    "    def empty(self):\n",
    "        return len( self._heap )==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the functions above, implement a function that takes in\n",
    "\n",
    "# 1) the value of k;\n",
    "# 2) the feature matrix for the training houses; and\n",
    "# 3) the feature vector of the query house\n",
    "\n",
    "# and returns the indices of the k closest training houses. For instance,\n",
    "# with 2-nearest neighbor, a return value of [5, 10] would indicate that\n",
    "# the 6th and 11th training houses are closest to the query house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(k, dataset, query):\n",
    "    PQ = PriorityQueue(key=lambda x: x[1])\n",
    "    dist2neighbors = distance_to_neighbors(dataset, query)\n",
    "    for index,distance in enumerate(dist2neighbors):\n",
    "        PQ.push( (index,distance) )\n",
    "    result = []\n",
    "    while not PQ.empty() and k != 0:\n",
    "        index = PQ.top()[0]\n",
    "        result.append(index)\n",
    "        k -= 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUIZ QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the query house to be third house of the test set (features_test[2]).\n",
    "# What are the indices of the 4 training houses closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[382, 1149, 4087, 3142]\n"
     ]
    }
   ],
   "source": [
    "print nearest_neighbors(4, features_train, features_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a single prediction by averaging k nearest neighbor outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know how to find the k-nearest neighbors, write a function that\n",
    "# predicts the value of a given query house. For simplicity, take the average\n",
    "# of the prices of the k nearest neighbors in the training set. The function\n",
    "# should have the following parameters:\n",
    "\n",
    "# 1) the value of k;\n",
    "# 2) the feature matrix for the training houses;\n",
    "# 3) the output values (prices) of the training houses; and\n",
    "# 4) the feature vector of the query house, whose price we are predicting.\n",
    "\n",
    "# The function should return a predicted value of the query house.\n",
    "\n",
    "# Hint: You can extract multiple items from a Numpy array using a list of indices.\n",
    "# For instance, output_train[[6, 10]] returns the prices of the 7th and 11th training\n",
    "# houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictkNN(k, dataset, output, query):\n",
    "    indices = nearest_neighbors(k=k, dataset=dataset, query=query)\n",
    "    return np.sum(output[indices]) / len(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUIZ QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again taking the query house to be third house of the test set (features_test[2]),\n",
    "# predict the value of the query house using k-nearest neighbors with k=4 and the\n",
    "# simple averaging method described and implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413987\n"
     ]
    }
   ],
   "source": [
    "print predictkNN(4, features_train, output_train, features_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare this predicted value using 4-nearest neighbors to the predicted value using\n",
    "# 1-nearest neighbor computed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249000\n"
     ]
    }
   ],
   "source": [
    "print predictkNN(1, features_train, output_train, features_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiple predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to predict the value of each and every house in a query set. (The query set\n",
    "# can be any subset of the dataset, be it the test set or validation set.) The idea is to have\n",
    "# a loop where we take each house in the query set as the query house and make a prediction for\n",
    "# that specific house. The new function should take the following parameters:\n",
    "\n",
    "# 1) the value of k;\n",
    "# 2) the feature matrix for the training houses;\n",
    "# 3) the output values (prices) of the training houses; and\n",
    "# 4) the feature matrix for the query set.\n",
    "\n",
    "# The function should return a set of predicted values, one for each house in the query set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_predictkNN(k, dataset, output, queryset):\n",
    "    result = []\n",
    "    for _,query in enumerate(queryset):\n",
    "        result.append( predictkNN(k, dataset, output, query) )\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUIZ QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the first 10 houses in the test set using k-nearest neighbors with k=10.\n",
    "\n",
    "# 1) What is the index of the house in this query set that has the lowest predicted value?\n",
    "# 2) What is the predicted value of this house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[881300,\n",
       " 431860,\n",
       " 460595,\n",
       " 430200,\n",
       " 766750,\n",
       " 667420,\n",
       " 350032,\n",
       " 512800,\n",
       " 484000,\n",
       " 457235]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_predictkNN(10, features_train, output_train, features_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Index=6, predicted value = 350032"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There remains a question of choosing the value of k to use in making predictions.\n",
    "# Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "# For k in [1, 2, ..., 15]:\n",
    "#   Makes predictions for each house in the VALIDATION set using the k-nearest neighbors from the TRAINING set.\n",
    "#   Computes the RSS for these predictions on the VALIDATION set\n",
    "#   Stores the RSS computed above in rss_all\n",
    "#   Report which k produced the lowest RSS on VALIDATION set.\n",
    "\n",
    "# (Depending on your computing environment, this computation may take 10-15 minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "RSS: 1.054512e+14\n",
      "k = 2\n",
      "RSS: 8.344507e+13\n",
      "k = 3\n",
      "RSS: 7.269211e+13\n",
      "k = 4\n",
      "RSS: 7.193481e+13\n",
      "k = 5\n",
      "RSS: 6.984652e+13\n",
      "k = 6\n",
      "RSS: 6.890312e+13\n",
      "k = 7\n",
      "RSS: 6.833833e+13\n",
      "k = 8\n",
      "RSS: 6.736170e+13\n",
      "k = 9\n",
      "RSS: 6.837275e+13\n",
      "k = 10\n",
      "RSS: 6.933357e+13\n",
      "k = 11\n",
      "RSS: 6.952388e+13\n",
      "k = 12\n",
      "RSS: 6.905197e+13\n",
      "k = 13\n",
      "RSS: 7.001127e+13\n",
      "k = 14\n",
      "RSS: 7.091156e+13\n",
      "k = 15\n",
      "RSS: 7.110883e+13\n",
      "best_k = 8, best_rss = 6.736170e+13\n"
     ]
    }
   ],
   "source": [
    "RSS = lambda output, predictions : sum((output - predictions)**2)\n",
    "rss_all = []\n",
    "best_rss = None\n",
    "best_k = None\n",
    "for k in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "    print \"k = %d\" % k\n",
    "    \n",
    "    pred = multiple_predictkNN(k, features_train, output_train, features_valid)\n",
    "    \n",
    "    rss_all.append( RSS(output_valid, pred) )\n",
    "    \n",
    "    print \"RSS: %e\" % rss_all[-1]\n",
    "    \n",
    "    if best_rss is None or rss_all[-1] < best_rss:\n",
    "        best_rss = rss_all[-1]\n",
    "        best_k = k\n",
    "\n",
    "print \"best_k = %d, best_rss = %e\" % (best_k, best_rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2199615710>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "kvals = range(1, 16)\n",
    "plt.plot(kvals, rss_all,'bo-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUIZ QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the RSS on the TEST data using the value of k found above?\n",
    "# To be clear, sum over all houses in the TEST set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.330917e+14\n"
     ]
    }
   ],
   "source": [
    "pred = multiple_predictkNN(8, features_train, output_train, features_test)\n",
    "    \n",
    "print \"%e\" % RSS(output_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
